# Phase 3: Implementation of Approach 1 - CycleGAN

## Understanding CycleGAN Structure

1. **Two Generators**:
   - G_A2B (Generator A to B): Converts from real human photos to anime
   - G_B2A (Generator B to A): Converts from anime to real human photos

2. **Two Discriminators**:
   - D_A: Distinguishes between real and fake human photos
   - D_B: Distinguishes between real and fake anime images

3. **Loss Types**:
   - Adversarial Loss: Regular GAN loss
   - Cycle Consistency Loss: Ensures A→B→A ≈ A and B→A→B ≈ B
   - Identity Loss (optional): Ensures G_A2B(B) ≈ B and G_B2A(A) ≈ A

## Creating Directory Structure for Source Code

```
src/
  ├── models/
  │   └── cyclegan/
  │       ├── model.py       # Model architecture definition
  │       ├── networks.py    # Generator, Discriminator network definitions
  │       └── utils.py       # Utility functions
  ├── training/
  │   └── train_cyclegan.py  # Training script
  ├── utils/
  │   ├── data_loader.py     # Data processing
  │   └── utils.py           # Common utility functions
  └── inference/
      └── cyclegan_inference.py  # Inference script
```

## Starting with Generator and Discriminator Network Definitions

File `src/models/cyclegan/networks.py` 
1. Generator uses ResNet architecture with ResidualBlocks
2. Discriminator uses PatchGAN architecture, evaluating small patches instead of entire image
3. Uses InstanceNorm instead of BatchNorm as it works better for style transfer
4. Final Tanh layer in Generator to normalize output to range [-1, 1]


## Defining the Complete CycleGAN Model

File `src/models/cyclegan/model.py` 
1. Initialize generators and discriminators
2. Define loss functions
3. Initialize optimizers
4. `forward` method to create fake and reconstructed images
5. `backward` methods to calculate and update gradients
6. `optimize_parameters` method to update parameters in one iteration
7. Methods to save and load models

## Creating DataLoader

File `src/utils/data_loader.py`:
1. Read images from both domains (real human and anime)
2. Apply transforms like resize, crop, flip, and normalize
3. Ensure images from both domains are randomly paired during training

## Writing Training Script

File `src/training/train_cyclegan.py`
1. Use `argparse` to customize training parameters via command-line
2. Create output directories to save results and checkpoints
3. Save generated images and loss plots after each epoch to track training
4. Use tqdm to display progress bar

## Writing Inference Script

File `src/inference/cyclegan_inference.py`:
1. Run inference on a single image or directory containing multiple images
2. Use trained Generator model
3. Save results to output directory

## How to Run the Code

1. **Train the model**:
```bash
python src/training/train_cyclegan.py --person_root data/processed/CelebA/train --anime_root data/processed/AnimeFace/train --person_val_root data/processed/CelebA/val --anime_val_root data/processed/AnimeFace/val --epochs 50 --batch_size 8
```

Output:
```
Domain A: 800 images
Domain B: 800 images
Domain A: 100 images
Domain B: 100 images
Starting training for 50 epochs...
Epoch 1/50:   0%|                                                               | 0/100 [00:00<?, ?it/s][1/50][0/100] Loss_D_A: 0.8182 Loss_D_B: 1.6169 Loss_G_A2B: 2.5171 Loss_G_B2A: 1.0364 Loss_cycle_A: 6.6629 Loss_cycle_B: 6.5283
Epoch 1/50: 100%|█████████████████████████████████████████████████████| 100/100 [02:01<00:00,  1.21s/it]
Epoch 1 completed in 121.45s
[...]
Epoch 50/50:   0%|                                                              | 0/100 [00:00<?, ?it/s][50/50][0/100] Loss_D_A: 0.1330 Loss_D_B: 0.1281 Loss_G_A2B: 0.5171 Loss_G_B2A: 0.4763 Loss_cycle_A: 1.2726 Loss_cycle_B: 1.1224
Epoch 50/50: 100%|████████████████████████████████████████████████████| 100/100 [02:02<00:00,  1.23s/it]
Epoch 50 completed in 123.12s
Training completed. Results saved to results/cyclegan_2025-04-22_11-43-11
```

2. **Run inference**:
```bash
python src/inference/cyclegan_inference.py --input_path path/to/your/image.jpg --model_path results/cyclegan_YYYY-MM-DD_HH-MM-SS/checkpoints/G_A2B_epoch_50.pth --output_dir results/inference
```