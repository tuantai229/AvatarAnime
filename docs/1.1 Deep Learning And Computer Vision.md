# CNN and Popular Architectures

### Convolutional Neural Network (CNN)
CNN is the foundation for most modern image processing applications. They work effectively with grid-structured data like images through key components:

1. **Convolutional layers**: Extract features from input images by applying filters (kernels) to create feature maps
2. **Pooling layers**: Reduce the spatial dimensions of feature maps (usually max pooling or average pooling)
3. **Activation functions**: Add non-linearity, most commonly ReLU
4. **Fully connected layers**: Connect all features to make final predictions

### Popular CNN Architectures

**1. VGG (Visual Geometry Group)**
- Simple architecture with stacked 3x3 convolutional layers
- Advantages: Simple, understandable, and effective for many problems
- Disadvantages: Large number of parameters, especially in fully connected layers

**2. ResNet (Residual Networks)**
- Breakthrough with "skip connections" to solve the vanishing gradient problem
- Allows building very deep networks (50, 101, even 152 layers)
- Advantages: Easy to optimize, high performance, scalable depth

**3. EfficientNet**
- Uses neural architecture search (NAS) and efficient model scaling
- Balances depth, width, and resolution of the network
- Advantages: High performance with fewer parameters

## Image Processing Techniques

### Normalization
- **Min-Max Scaling**: Brings pixel values to the [0,1] range
- **Standardization**: Normalizes data to distribution with mean 0, standard deviation 1
- **Batch Normalization**: Normalizes activations within the network, helping stabilize learning

### Data Augmentation
Very important for this project to increase data size and diversity:
- **Geometric transformations**: Rotation, flipping, cropping, zooming
- **Color transformations**: Changing brightness, contrast, saturation
- **Random erasing/cutout**: Randomly erasing parts of images to increase robustness

### Image Transformations
- **Resize**: Adjusting image size to fit model input
- **Cropping**: Cutting region of interest (ROI)
- **Color space conversions**: Converting between RGB, HSV, Lab, etc.

## Image-to-Image Translation and Style Transfer

### Image-to-Image Translation
This is the core problem of our project, converting an image from source domain to target domain while preserving content.

- **Paired translation**: Using corresponding image pairs from both domains (e.g., pix2pix)
- **Unpaired translation**: No need for corresponding image pairs, just sets of images from each domain (e.g., CycleGAN)

### Style Transfer
Technique to transfer style from one image to another:

- **Neural Style Transfer**: Using CNN networks to extract content from source image and style from reference image
- **Adaptive Instance Normalization (AdaIN)**: Faster method for real-time style transfer
- **StyleGAN**: GAN architecture allowing control over multiple style aspects

## Evaluation Metrics

### Quantitative
- **Inception Score (IS)**: Evaluates quality and diversity of generated images
- **Fr√©chet Inception Distance (FID)**: Measures the difference between distributions of real and generated images
- **Structural Similarity Index (SSIM)**: Evaluates structural similarity between source and generated images
- **LPIPS (Learned Perceptual Image Patch Similarity)**: Measures perceptual differences based on learned features

### Qualitative
- **User surveys**: Evaluations of similarity, image quality, aesthetics
- **A/B testing**: Comparing results from different models

## Notes for Human-to-Anime Conversion Project

For this specific project, focus on:

1. **Identity preservation**: Using feature extraction and preservation techniques
2. **Anime style**: Learning to create characteristic lines, colors, and details of anime
3. **Input variations**: Building a model robust to different angles, lighting, expressions